{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7bf7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu fetch: https://vietnammoi.vn/lich-trinh-cac-tuyen-xe-buyt-tphcm-moi-nhat-2025-thoi-gian-gia-ve-lo-trinh-chi-tiet-202552415731119.htm\n",
      "Số bảng parsed: 155\n",
      "\n",
      "--- mẫu 1 ---\n",
      "route_code: None\n",
      "route_path preview: Chiều Bến Thành → Chợ Lớn: Công trường Mê Linh – Đường Thi Sách – Công trường Mê Linh – Đường Tôn Đức Thắng – Đường Hàm Nghi – Đường Trần Hưng Đạo – Đường Nguyễn Tri Phương – Đường Trần Phú – Đường Tr\n",
      "fare (type): <class 'list'>\n",
      "\n",
      "--- mẫu 2 ---\n",
      "route_code: 03\n",
      "route_path preview: Chiều Bến Thành → Thạnh Xuân: Bến xe buýt Sài Gòn – Đường Phạm Ngũ Lão – Đường Yersin – Đường Trần Hưng Đạo – Đường Hàm Nghi – Đường Hồ Tùng Mậu – Đường nhánh S2 – Đường Tôn Đức Thắng – Đường Hai Bà T\n",
      "fare (type): <class 'list'>\n",
      "\n",
      "--- mẫu 3 ---\n",
      "route_code: 04\n",
      "route_path preview: Chiều Bến Thành → Bến xe An Sương: Bến xe buýt Sài Gòn – Đường Phạm Ngũ Lão – Đường Yersin – Đường Trần Hưng Đạo – Đường Hàm Nghi – Đường Pasteur – Đường Võ Thị Sáu – Đường Nam Kỳ Khởi Nghĩa – Đường N\n",
      "fare (type): <class 'list'>\n",
      "Đã lưu: ../data/bus_routes.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scrape các table tuyến bus (table tr: field | value) từ bài VietNamMoi\n",
    "\"\"\"\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "\n",
    "URL = \"https://vietnammoi.vn/lich-trinh-cac-tuyen-xe-buyt-tphcm-moi-nhat-2025-thoi-gian-gia-ve-lo-trinh-chi-tiet-202552415731119.htm\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120 Safari/537.36\"}\n",
    "OUT_JSON = \"../data/bus_routes.json\"\n",
    "\n",
    "# mapping key (dùng substring match, case-insensitive)\n",
    "FIELD_MAP = {\n",
    "    \"mã số tuyến\": \"route_code\",\n",
    "    \"mã số\": \"route_code\",\n",
    "    \"tuyến\": \"route_name\",\n",
    "    \"lộ trình\": \"route_path\",\n",
    "    \"cự ly\": \"distance_km\",\n",
    "    \"thời gian hoạt động\": \"service_hours\",\n",
    "    \"giá vé\": \"fare\",\n",
    "    \"giá\": \"fare\",\n",
    "    \"số chuyến\": \"trips_per_day\",\n",
    "    \"thời gian chuyến\": \"trip_time\",\n",
    "    \"giãn cách\": \"headway\"\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "# util\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "def clean_text(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return re.sub(r'\\s+', ' ', unescape(str(s)).strip()).strip()\n",
    "\n",
    "def request_get_with_retry(url, headers, timeout=30, retries=2, backoff=1.0):\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            return r\n",
    "        except Exception as e:\n",
    "            if attempt == retries:\n",
    "                raise\n",
    "            time.sleep(backoff * (attempt + 1))\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "# parsing helpers\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "def parse_value_cell(cell):\n",
    "    \"\"\"\n",
    "    Trả:\n",
    "      - list (items) nếu cell chứa <ul>/<li> hoặc nhiều <p> (ví dụ giá vé)\n",
    "      - string nếu chỉ 1 đoạn text\n",
    "    \"\"\"\n",
    "    if cell is None:\n",
    "        return \"\"\n",
    "\n",
    "    # nếu có danh sách <ul><li>\n",
    "    ul = cell.find(\"ul\")\n",
    "    if ul:\n",
    "        items = []\n",
    "        for li in ul.find_all(\"li\"):\n",
    "            items.append(clean_text(li.get_text()))\n",
    "        if items:\n",
    "            return items\n",
    "\n",
    "    # nếu có nhiều <p> trực tiếp (không đếm nested), trả list\n",
    "    ps = [p for p in cell.find_all(\"p\", recursive=False) if clean_text(p.get_text())]\n",
    "    if ps and len(ps) > 1:\n",
    "        return [clean_text(p.get_text()) for p in ps]\n",
    "\n",
    "    # nếu có nhiều dòng trong text, nhưng không phải <p> nhiều thì tách dòng và trả list nếu nhiều dòng\n",
    "    text = clean_text(cell.get_text())\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    if len(lines) > 1:\n",
    "        return lines\n",
    "\n",
    "    return text\n",
    "\n",
    "def map_field_name(key_raw):\n",
    "    key = clean_text(key_raw).lower()\n",
    "    for pattern, mapped in FIELD_MAP.items():\n",
    "        if pattern in key:\n",
    "            return mapped\n",
    "    # fallback: slugify\n",
    "    return re.sub(r'[^a-z0-9]+', '_', key)\n",
    "\n",
    "def join_if_list_except_fare(val, field_name):\n",
    "    \"\"\"\n",
    "    Nếu val là list và field != 'fare' => join thành chuỗi để dễ xử lý bằng regex\n",
    "    Giữ list cho 'fare' để giữ nhiều mức giá.\n",
    "    \"\"\"\n",
    "    if isinstance(val, list) and field_name != \"fare\":\n",
    "        return \" \".join(str(x) for x in val)\n",
    "    return val\n",
    "\n",
    "# tách directions/stops từ route_path string\n",
    "def split_directions(route_path_text):\n",
    "    if not route_path_text:\n",
    "        return None, None, [], []\n",
    "    txt = route_path_text\n",
    "\n",
    "    # match các khối \"Chiều ... : <nội dung>\"\n",
    "    matches = re.findall(r'(?i)(Chiều[^:]{1,80}?)\\s*:\\s*(.+?)(?=(?:Chiều\\s[^:]{1,80}?:)|$)', txt, flags=re.S)\n",
    "    dir_a = dir_b = None\n",
    "    if matches:\n",
    "        if len(matches) >= 1:\n",
    "            dir_a = clean_text(matches[0][1])\n",
    "        if len(matches) >= 2:\n",
    "            dir_b = clean_text(matches[1][1])\n",
    "    else:\n",
    "        # fallback: nếu có kí hiệu mũi tên → thì coi cả chuỗi làm direction_a\n",
    "        if \"→\" in txt:\n",
    "            dir_a = clean_text(txt)\n",
    "\n",
    "    def stops_from(s):\n",
    "        if not s:\n",
    "            return []\n",
    "        parts = re.split(r'\\s*[–\\-—–]\\s*', s)\n",
    "        return [clean_text(p) for p in parts if clean_text(p)]\n",
    "\n",
    "    stops_a = stops_from(dir_a)\n",
    "    stops_b = stops_from(dir_b)\n",
    "    return dir_a, dir_b, stops_a, stops_b\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "# table parsing\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "def parse_table(tbl, page_url):\n",
    "    obj = {\"raw_html\": str(tbl), \"page_url\": page_url}\n",
    "    for tr in tbl.find_all(\"tr\"):\n",
    "        tds = tr.find_all([\"td\", \"th\"])\n",
    "        if len(tds) < 2:\n",
    "            continue\n",
    "        key_raw = tds[0].get_text()\n",
    "        val_cell = tds[1]\n",
    "        mapped = map_field_name(key_raw)\n",
    "        val = parse_value_cell(val_cell)\n",
    "        # nếu val là list và field không phải fare thì join để xử lý sau (regex)\n",
    "        val = join_if_list_except_fare(val, mapped)\n",
    "        # gán (nếu key trùng, merge thành list)\n",
    "        if mapped in obj:\n",
    "            existing = obj[mapped]\n",
    "            if isinstance(existing, list):\n",
    "                if isinstance(val, list):\n",
    "                    existing.extend(val)\n",
    "                else:\n",
    "                    existing.append(val)\n",
    "            else:\n",
    "                obj[mapped] = [existing, val]\n",
    "        else:\n",
    "            obj[mapped] = val\n",
    "\n",
    "    # chắc chắn route_path là str trước khi tách direction\n",
    "    if \"route_path\" in obj:\n",
    "        if isinstance(obj[\"route_path\"], list):\n",
    "            obj[\"route_path\"] = \" \".join(obj[\"route_path\"])\n",
    "        dir_a, dir_b, stops_a, stops_b = split_directions(obj.get(\"route_path\", \"\"))\n",
    "        if dir_a:\n",
    "            obj[\"direction_a\"] = dir_a\n",
    "        if dir_b:\n",
    "            obj[\"direction_b\"] = dir_b\n",
    "        if stops_a:\n",
    "            obj[\"stops_a\"] = stops_a\n",
    "        if stops_b:\n",
    "            obj[\"stops_b\"] = stops_b\n",
    "\n",
    "    # chuẩn hoá distance\n",
    "    if \"distance_km\" in obj and isinstance(obj[\"distance_km\"], str):\n",
    "        obj[\"distance_km\"] = obj[\"distance_km\"].replace(',', '.').strip()\n",
    "\n",
    "    # trips_per_day về int nếu có\n",
    "    if \"trips_per_day\" in obj and isinstance(obj[\"trips_per_day\"], str):\n",
    "        m = re.search(r'(\\d+)', obj[\"trips_per_day\"])\n",
    "        if m:\n",
    "            try:\n",
    "                obj[\"trips_per_day\"] = int(m.group(1))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return obj\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "# main scraping flow\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "def scrape(url):\n",
    "    r = request_get_with_retry(url, HEADERS, retries=2, backoff=1.0)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    article = soup.find(\"div\", {\"itemprop\": \"articleBody\"}) or soup.find(\"article\") or soup.find(\"div\", {\"class\": \"article-content\"}) or soup.body\n",
    "    tables = article.find_all(\"table\")\n",
    "    results = []\n",
    "    for tbl in tables:\n",
    "        parsed = parse_table(tbl, url)\n",
    "        # giữ nếu có ít nhất route_path hoặc route_code/name\n",
    "        if parsed.get(\"route_path\") or parsed.get(\"route_code\") or parsed.get(\"route_name\"):\n",
    "            results.append(parsed)\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Bắt đầu fetch:\", URL)\n",
    "    data = scrape(URL)\n",
    "    print(\"Số bảng parsed:\", len(data))\n",
    "    # in 3 mẫu đầu để kiểm tra\n",
    "    for i, d in enumerate(data[:3], start=1):\n",
    "        print(f\"\\n--- mẫu {i} ---\")\n",
    "        print(\"route_code:\", d.get(\"route_code\"))\n",
    "        print(\"route_path preview:\", (d.get(\"route_path\") or \"\")[:200])\n",
    "        print(\"fare (type):\", type(d.get(\"fare\")))\n",
    "    # lưu file\n",
    "    with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(\"Đã lưu:\", OUT_JSON)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
