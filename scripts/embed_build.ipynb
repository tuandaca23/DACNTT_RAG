{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f69953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số chunk cần embed: 7604\n",
      "Đang dùng mô hình SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 238/238 [02:53<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu embeddings tại: d:\\RAG\\data\\embeddings.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def embed_documents(provider='sentence-transformers'):\n",
    "    # Nếu đang ở thư mục /scripts thì lùi lên gốc project\n",
    "    base_dir = Path.cwd().parent if Path.cwd().name == \"scripts\" else Path.cwd()\n",
    "    data_dir = base_dir / \"data\"\n",
    "\n",
    "    input_file = data_dir / \"chunked_docs.json\"\n",
    "    output_file = data_dir / \"embeddings.npy\"\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    texts = [chunk['content'] for chunk in chunks]\n",
    "\n",
    "    print(f\"Tổng số chunk cần embed: {len(texts)}\")\n",
    "\n",
    "    if provider == 'sentence-transformers':\n",
    "        print(\"Đang dùng mô hình SentenceTransformer: all-MiniLM-L6-v2\")\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "    elif provider == 'openai':\n",
    "        print(\"Đang dùng mô hình OpenAI: text-embedding-ada-002\")\n",
    "        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            response = client.embeddings.create(input=text, model='text-embedding-ada-002')\n",
    "            embeddings.append(response.data[0].embedding)\n",
    "        embeddings = np.array(embeddings)\n",
    "\n",
    "    np.save(output_file, embeddings)\n",
    "    print(f\"Đã lưu embeddings tại: {output_file}\")\n",
    "\n",
    "\n",
    "embed_documents(provider='sentence-transformers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b095774",
   "metadata": {},
   "source": [
    "### Embeddings pdf chunks chuẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adfe8d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 85/85 [00:21<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings: ../data/embeddings.npy index: ../data/faiss_index.ivf meta: ../data/embeddings_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json, os, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "IN = \"../data/pdf_chunks_cleaned_for_embed_v3.json\"\n",
    "EMB_OUT = \"../data/embeddings.npy\"\n",
    "META_OUT = \"../data/embeddings_meta.json\"\n",
    "INDEX_OUT = \"../data/faiss_index.ivf\"\n",
    "\n",
    "BATCH = 64\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\" \n",
    "os.makedirs(os.path.dirname(EMB_OUT), exist_ok=True)\n",
    "\n",
    "# 1) load chunks\n",
    "with open(IN,\"r\",encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "texts = [c[\"text_for_embed\"] for c in chunks]\n",
    "meta  = [{\"chunk_id\": c.get(\"id\"), \n",
    "          \"source_chunk_id\": c.get(\"source_chunk_id\"), \n",
    "          \"page\": c.get(\"page\")} \n",
    "          for c in chunks]\n",
    "\n",
    "# 2) embed in batches\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "embs = []\n",
    "for i in tqdm(range(0, len(texts), BATCH)):\n",
    "    batch = texts[i:i+BATCH]\n",
    "    e = model.encode(batch, show_progress_bar=False, convert_to_numpy=True)\n",
    "    embs.append(e)\n",
    "embs = np.vstack(embs).astype(\"float32\")\n",
    "np.save(EMB_OUT, embs)\n",
    "with open(META_OUT,\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False)\n",
    "\n",
    "# 3) build Faiss index (IVF + PQ optional). Simpler: IndexFlatIP if small.\n",
    "d = embs.shape[1]\n",
    "index = faiss.IndexFlatIP(d)          # cosine-like if vectors normalized\n",
    "faiss.normalize_L2(embs)\n",
    "index.add(embs)\n",
    "faiss.write_index(index, INDEX_OUT)\n",
    "print(\"Saved embeddings:\", EMB_OUT, \n",
    "      \"index:\", INDEX_OUT, \n",
    "      \"meta:\", META_OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
